{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import skimage\n",
    "import fnmatch\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "from PIL import Image\n",
    "import re\n",
    "import pickle\n",
    "\n",
    "\n",
    "def resize_2d_nonan(array,factor):\n",
    "    \"\"\"\n",
    "    intial author: damo_ma\n",
    "    \"\"\"\n",
    "    xsize, ysize = array.shape\n",
    "\n",
    "    if isinstance(factor,int):\n",
    "        factor_x = factor\n",
    "        factor_y = factor\n",
    "    elif isinstance(factor,tuple):\n",
    "        factor_x , factor_y = factor[0], factor[1]\n",
    "    else:\n",
    "        raise NameError('Factor must be a tuple (x,y) or an integer')\n",
    "\n",
    "    if not (xsize %factor_x == 0 or ysize % factor_y == 0) :\n",
    "        raise NameError('Factors must be intger multiple of array shape')\n",
    "\n",
    "    new_xsize, new_ysize = xsize//factor_x, ysize//factor_y\n",
    "\n",
    "    new_array = np.empty([new_xsize, new_ysize])\n",
    "    new_array[:] = np.nan # this saves us an assignment in the loop below\n",
    "\n",
    "    # submatrix indexes : is the average box on the original matrix\n",
    "    subrow, subcol  = np.indices((factor_x, factor_y))\n",
    "\n",
    "     # new matrix indexs\n",
    "    row, col  = np.indices((new_xsize, new_ysize))\n",
    "\n",
    "    for i, j, ind in zip(row.reshape(-1), col.reshape(-1),range(row.size)) :\n",
    "        # define the small sub_matrix as view of input matrix subset\n",
    "        sub_matrix = array[subrow+i*factor_x,subcol+j*factor_y]\n",
    "        # modified from any(a) and all(a) to a.any() and a.all()\n",
    "        # see https://stackoverflow.com/a/10063039/1435167\n",
    "        if (np.isnan(sub_matrix)).sum() < (factor_x*factor_y)/2.0 + (np.random.rand() -0.5): # if we haven't all NaN\n",
    "            if (np.isnan(sub_matrix)).any(): # if we haven no NaN at all\n",
    "                (new_array.reshape(-1))[ind] = np.nanmean(sub_matrix)\n",
    "            else: # if we haven some NaN\n",
    "                (new_array.reshape(-1))[ind] = np.mean(sub_matrix)\n",
    "        # the case assign NaN if we have all NaN is missing due \n",
    "        # to the standard values of new_array\n",
    "\n",
    "    return new_array\n",
    "\n",
    "\n",
    "def load_pfm(fname):\n",
    "    color = None\n",
    "    width = None\n",
    "    height = None\n",
    "    scale = None\n",
    "    endian = None\n",
    "\n",
    "    file = open(fname,'r',encoding='iso-8859-1')\n",
    "    header = file.readline().rstrip()\n",
    "    if header == 'PF':\n",
    "        color = True\n",
    "    elif header == 'Pf':\n",
    "        color = False\n",
    "    else:\n",
    "        raise Exception('Not a PFM file.')\n",
    "\n",
    "    dim_match = re.match(r'^(\\d+)\\s(\\d+)\\s$', file.readline())\n",
    "    if dim_match:\n",
    "        width, height = map(int, dim_match.groups())\n",
    "    else:\n",
    "        raise Exception('Malformed PFM header.')\n",
    "\n",
    "    scale = float(file.readline().rstrip())\n",
    "    if scale < 0: # little-endian\n",
    "        endian = '<'\n",
    "        scale = -scale\n",
    "    else:\n",
    "        endian = '>' # big-endian\n",
    "\n",
    "    data = np.fromfile(file, endian + 'f')\n",
    "    shape = (height, width, 3) if color else (height, width)\n",
    "    return np.flipud(np.reshape(data, shape)), scale\n",
    "def load_calibtxt(fname):\n",
    "    file = open(fname,'rt',encoding='iso-8859-1')\n",
    "    return {l.split('=')[0]:' '.join(l.split('=')[1:]).rstrip() for l in [line for line in file]}\n",
    "def cf(num1,num2):\n",
    "    n=[]\n",
    "    for i in range(1, min(num1, num2)+1): \n",
    "        if num1%i==num2%i==0: \n",
    "            n.append(i)\n",
    "    return n\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "in_fold = 'data/middlebury/middle_custom/'\n",
    "out_fold = 'data/middlebury/mid_out2'\n",
    "target_size = 215000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.exists(out_fold):\n",
    "    os.mkdir(out_fold)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_dirs = sorted([_ for _ in os.listdir(in_fold) if os.path.exists(os.path.join(in_fold,_,'im0.png'))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for tdir in target_dirs:\n",
    "    #if 'perfect' in tdir: continue\n",
    "\n",
    "    im0 = skimage.io.imread(os.path.join(in_fold,tdir,'im0.png'))\n",
    "    im1 = skimage.io.imread(os.path.join(in_fold,tdir,'im1.png'))\n",
    "    scales = [(i,np.prod(im0.shape[:2])/(i*i)) for i in cf(*im0.shape[:2])]\n",
    "    scales = sorted([(abs(np.log(target_size/_[1])),_[0],_[1]) for _ in scales])\n",
    "    scale = scales[0][1]\n",
    "    im0 = skimage.transform.downscale_local_mean(im0,(scale,scale,1))\n",
    "    im1 = skimage.transform.downscale_local_mean(im1,(scale,scale,1))\n",
    "    gt,s = load_pfm(os.path.join(in_fold,tdir,'disp0.pfm'))\n",
    "    gt2 = resize_2d_nonan(gt,scale)/scale\n",
    "    max_disp = int(load_calibtxt(os.path.join(in_fold,tdir,'calib.txt'))['ndisp'])\n",
    "    max_disp = int(load_calibtxt(os.path.join(in_fold,tdir,'calib.txt'))['ndisp'])\n",
    "    max_disp = int(np.ceil(max_disp/scale))\n",
    "    max_disp= max(16,max_disp)\n",
    "    max_disp = (max_disp//16+1)*16 if max_disp//16 != max_disp/16 else max_disp\n",
    "    print(tdir,scale,max_disp)\n",
    "    \n",
    "    gt_d2,s_d2 = load_pfm(os.path.join(in_fold,tdir,'disp1.pfm'))\n",
    "    gt2_d2 = resize_2d_nonan(gt_d2,scale)/scale\n",
    "\n",
    "    new_img = []\n",
    "    fine_thresh =1\n",
    "    for row1,row2 in zip(gt2,gt2_d2):\n",
    "        s_d = np.arange(len(row1))-row1\n",
    "        v2 = np.round(np.clip(s_d,0,len(row1)-1)).astype(int)\n",
    "        vdiff = np.nan_to_num(abs(row1-row2[v2]))\n",
    "        new_img.append(vdiff > fine_thresh)\n",
    "\n",
    "    \n",
    "    out_d = {\n",
    "        'im0': np.round(im0).astype(np.uint8),\n",
    "        'im1': np.round(im1).astype(np.uint8),\n",
    "        'max_disp': max_disp,\n",
    "        'gt': gt2,\n",
    "        'mask': np.array(new_img)\n",
    "    }\n",
    "    \n",
    "    with open(os.path.join(out_fold,\"{}.pkl\".format(tdir)), \"wb\") as f: \n",
    "        pickle.dump(out_d, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = ['P1', 'P2', 'blockSize', 'disp12MaxDiff', 'preFilterCap', 'speckleRange', 'speckleWindowSize', 'uniquenessRatio']\n",
    "x0 = np.log(np.array([216, 864, 5, 40, 63, 2, 0.1, 15]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "errs = []\n",
    "disps = []\n",
    "for tdir in target_dirs:\n",
    "    \n",
    "    with open(os.path.join(out_fold,\"{}.pkl\".format(tdir)), \"rb\") as f: \n",
    "        out_d = pickle.load(f)\n",
    "    \n",
    "    params = x0\n",
    "    p = {\n",
    "        'blockSize': 5,\n",
    "        'P1':8 * 3 * 3 ** 2,\n",
    "        'P2':32 * 3 * 3 ** 2,\n",
    "        'disp12MaxDiff': 40,\n",
    "        'uniquenessRatio': 15,\n",
    "        'speckleWindowSize': 0,\n",
    "        'speckleRange': 2,\n",
    "        'preFilterCap': 63,\n",
    "    }\n",
    "\n",
    "    p['minDisparity'] = 0\n",
    "    p['numDisparities'] = out_d['max_disp']\n",
    "    p['mode'] = cv2.STEREO_SGBM_MODE_SGBM\n",
    "\n",
    "    for c,v in zip(cols,params):\n",
    "        p[c] = int(round(np.exp(v)))\n",
    "\n",
    "    left_matcher = cv2.StereoSGBM_create(**p)\n",
    "\n",
    "    max_disp = out_d['max_disp']\n",
    "    imL = np.pad(out_d['im0'], [(0,0), (max_disp,0), (0,0)],mode='constant')\n",
    "    imR = np.pad(out_d['im1'], [(0,0), (max_disp,0), (0,0)],mode='constant')\n",
    "    displ = left_matcher.compute(imL, imR)[:,max_disp:]\n",
    "    result = (displ).astype(np.float32)/16\n",
    "    max_error = 3\n",
    "\n",
    "    err_vec = np.nan_to_num(abs(result-out_d['gt']))\n",
    "    err_vec[err_vec > max_error] = max_error\n",
    "    err_vec[displ == -1] = max_error\n",
    "    err = np.mean(err_vec)\n",
    "    errs.append(err)\n",
    "    disps.append(max_disp)\n",
    "    \n",
    "np.mean(errs),np.std(errs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a  = len(errs)//2\n",
    "b = len(errs)-a\n",
    "s = [True]*a + [False]*b\n",
    "import random\n",
    "combos = [] \n",
    "for i in range(10000000): # 10000000\n",
    "    combos.append(tuple(sorted(s, key=lambda k: random.random())))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools\n",
    "e_arr = np.array(errs)\n",
    "d_arr = np.array(disps)\n",
    "err_val ={}\n",
    "b_val ={}\n",
    "\n",
    "for combo in combos:    \n",
    "    c_arr = np.array(combo)\n",
    "    big_err = [abs(f(e_arr[c_arr])-f(e_arr[~c_arr])) for f in [np.mean,np.std]] + \\\n",
    "              [abs(f(d_arr[c_arr])-f(d_arr[~c_arr])) for f in [np.mean,np.std]]\n",
    "    err_val[combo] = np.prod(big_err)\n",
    "    b_val[combo] = big_err\n",
    "ideal_res = sorted([(v,np.where(k)[0],k) for k,v in err_val.items()])\n",
    "ideal_res_tmp = sorted([(v,np.where(k)[0]) for k,v in err_val.items()])\n",
    "\n",
    "ideal_res_tmp[:3],b_val[ideal_res[0][2]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "big_err"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
